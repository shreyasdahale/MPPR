{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fdede0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.linear_model import Ridge\n",
    "from matplotlib.colors import Normalize\n",
    "import networkx as nx\n",
    "from scipy.signal import welch\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52baae13",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9b6f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 6330\n"
     ]
    }
   ],
   "source": [
    "class LSTMBaseline3D:\n",
    "    \"\"\"\n",
    "    Lightweight single-layer LSTM for 3-dim Lorenz forecasting.\n",
    "    * hidden_size=32 → ~4.8k trainable parameters\n",
    "    * fit() trains in teacher-forcing mode\n",
    "    * predict() produces autoregressive roll-out\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim:  int = 3,\n",
    "                 hidden_size: int = 37,\n",
    "                 output_dim: int = 3,\n",
    "                 lr: float = 1e-3,\n",
    "                 epochs: int = 30,\n",
    "                 device: str = 'cpu',\n",
    "                 seed: int = 0):\n",
    "        torch.manual_seed(seed); np.random.seed(seed)\n",
    "\n",
    "        self.device  = torch.device(device)\n",
    "        self.epochs  = epochs\n",
    "        self.model   = nn.LSTM(input_dim, hidden_size,\n",
    "                               batch_first=True).to(self.device)\n",
    "        self.head    = nn.Linear(hidden_size, output_dim).to(self.device)\n",
    "        self.crit    = nn.MSELoss()\n",
    "        self.optim   = Adam(list(self.model.parameters())+\n",
    "                            list(self.head.parameters()), lr=lr)\n",
    "        \n",
    "    def total_parameters(self):\n",
    "        total = 0\n",
    "        for param in list(self.model.parameters()) + list(self.head.parameters()):\n",
    "            total += param.numel()\n",
    "        return total\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    @torch.no_grad()\n",
    "    def _init_hidden(self, batch_sz=1):\n",
    "        h0 = torch.zeros(1, batch_sz,\n",
    "                         self.model.hidden_size,\n",
    "                         device=self.device)\n",
    "        c0 = torch.zeros_like(h0)\n",
    "        return (h0, c0)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    def fit(self, x_np: np.ndarray, y_np: np.ndarray):\n",
    "        \"\"\"\n",
    "        x_np shape [T, 3]  (input  at t)\n",
    "        y_np shape [T, 3]  (target at t)\n",
    "        \"\"\"\n",
    "        x = torch.tensor(x_np, dtype=torch.float32,\n",
    "                         device=self.device).unsqueeze(0)  # [1,T,3]\n",
    "        y = torch.tensor(y_np, dtype=torch.float32,\n",
    "                         device=self.device).unsqueeze(0)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            self.optim.zero_grad()\n",
    "            out, _ = self.model(x, self._init_hidden())\n",
    "            pred   = self.head(out)\n",
    "            loss   = self.crit(pred, y)\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    @torch.no_grad()\n",
    "    def predict(self, init_u: np.ndarray, n_steps: int):\n",
    "        \"\"\"\n",
    "        Autoregressive roll-out.\n",
    "        init_u : initial 3-vector (last known sample)\n",
    "        Returns array of shape [n_steps, 3].\n",
    "        \"\"\"\n",
    "        self.model.eval(); self.head.eval()\n",
    "\n",
    "        inp     = torch.tensor(init_u[None, None, :],\n",
    "                               dtype=torch.float32, device=self.device)\n",
    "        h, c    = self._init_hidden()\n",
    "        preds   = np.empty((n_steps, 3), dtype=np.float32)\n",
    "\n",
    "        for t in range(n_steps):\n",
    "            out, (h, c) = self.model(inp, (h, c))\n",
    "            y           = self.head(out)\n",
    "            preds[t]    = y.squeeze(0).cpu().numpy()\n",
    "            inp         = y.detach()    # feed prediction back\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_open_loop(self, x_np: np.ndarray):\n",
    "        \"\"\"\n",
    "        Open-loop prediction using teacher-forced inputs (like during training).\n",
    "        x_np shape: [T, 3] – input sequence\n",
    "        Returns:\n",
    "            preds: [T, 3] – predicted output sequence\n",
    "        \"\"\"\n",
    "        self.model.eval(); self.head.eval()\n",
    "\n",
    "        x = torch.tensor(x_np, dtype=torch.float32,\n",
    "                         device=self.device).unsqueeze(0)  # [1, T, 3]\n",
    "        out, _ = self.model(x, self._init_hidden())\n",
    "        preds = self.head(out).squeeze(0).cpu().numpy()  # [T, 3]\n",
    "\n",
    "        return preds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = LSTMBaseline3D()\n",
    "    print(f\"Total trainable parameters: {model.total_parameters()}\")\n",
    "\n",
    "# lstm_baseline = LSTMBaseline3D(\n",
    "#                     hidden_size=38,         # parameter budget ~ 4800\n",
    "#                     lr=1e-3,\n",
    "#                     epochs=100,\n",
    "#                     device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "#                     seed=45)\n",
    "# lstm_baseline.fit(train_input, train_target)\n",
    "\n",
    "# # one-step roll-out to build an initial vector for auto-regressive mode\n",
    "# init_vec = train_target[-1]                # last teacher-forced target\n",
    "# lstm_preds = lstm_baseline.predict(init_vec,\n",
    "#                                    n_steps=len(test_input))\n",
    "# lstm_preds_open_loop = lstm_baseline.predict_open_loop(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878d0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nrmse(all_preds, test_target, horizons):\n",
    "    \"\"\"\n",
    "    Evaluate model performance over multiple prediction horizons\n",
    "    for teacher-forced single-step forecasting or autoregressive rollout.\n",
    "    \"\"\"\n",
    "    horizon_nrmse = {}\n",
    "    for horizon in horizons:\n",
    "        preds = all_preds[:horizon]\n",
    "        targets = test_target[:horizon]\n",
    "        squared_errors = (preds - targets) ** 2\n",
    "        variance = np.var(targets, axis=0)\n",
    "        variance[variance == 0] = 1e-8  # avoid divide-by-zero\n",
    "        nrmse = np.sqrt(np.sum(squared_errors) / (horizon * np.sum(variance)))\n",
    "        horizon_nrmse[horizon] = nrmse\n",
    "    return horizon_nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a6add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_valid_prediction_time(y_true, y_pred, t_vals, threshold, lambda_max, dt):\n",
    "    \"\"\"\n",
    "    Compute the Valid Prediction Time (VPT) and compare it to Lyapunov time T_lambda = 1 / lambda_max.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : ndarray of shape (N, dim)\n",
    "        True trajectory over time.\n",
    "    y_pred : ndarray of shape (N, dim)\n",
    "        Model's predicted trajectory over time (closed-loop).\n",
    "    t_vals : ndarray of shape (N,)\n",
    "        Time values corresponding to the trajectory steps.\n",
    "    threshold : float, optional\n",
    "        The error threshold, default is 0.4 as in your snippet.\n",
    "    lambda_max : float, optional\n",
    "        Largest Lyapunov exponent. Default=0.9 for Lorenz.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    T_VPT : float\n",
    "        Valid prediction time. The earliest time at which normalized error surpasses threshold\n",
    "        (or the last time if never surpassed).\n",
    "    T_lambda : float\n",
    "        Lyapunov time = 1 / lambda_max\n",
    "    ratio : float\n",
    "        How many Lyapunov times the model prediction remains valid, i.e. T_VPT / T_lambda.\n",
    "    \"\"\"\n",
    "    # 1) Average of y_true\n",
    "    y_mean = np.mean(y_true, axis=0)  # shape (dim,)\n",
    "    \n",
    "    # 2) Time-averaged norm^2 of (y_true - y_mean)\n",
    "    y_centered = y_true - y_mean\n",
    "    denom = np.mean(np.sum(y_centered**2, axis=1))  # scalar\n",
    "    \n",
    "    # 3) Compute the normalized error delta_gamma(t) = ||y_true - y_pred||^2 / denom\n",
    "    diff = y_true - y_pred\n",
    "    err_sq = np.sum(diff**2, axis=1)  # shape (N,)\n",
    "    delta_gamma = err_sq / denom      # shape (N,)\n",
    "    \n",
    "    # 4) Find the first time index where delta_gamma(t) exceeds threshold\n",
    "    idx_exceed = np.where(delta_gamma > threshold)[0]\n",
    "    if len(idx_exceed) == 0:\n",
    "        # never exceeds threshold => set T_VPT to the final time\n",
    "        T_VPT = t_vals[-1]\n",
    "    else:\n",
    "        T_VPT = t_vals[idx_exceed[0]]\n",
    "    \n",
    "    # 5) Compute T_lambda and ratio\n",
    "    T_lambda = 1.0 / lambda_max\n",
    "\n",
    "    # print(f\"\\n--- Valid Prediction Time (VPT) with threshold={threshold}, lambda_max={lambda_max} ---\")\n",
    "\n",
    "    T_VPT = (T_VPT - t_vals[0])  # Adjust T_VPT to be relative to the start time\n",
    "    ratio = T_VPT / T_lambda\n",
    "\n",
    "    return T_VPT, T_lambda, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b5c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attractor_deviation(predictions, targets, cube_size=(0.1, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Compute the Attractor Deviation (ADev) metric.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (numpy.ndarray): Predicted trajectories of shape (n, 3).\n",
    "        targets (numpy.ndarray): True trajectories of shape (n, 3).\n",
    "        cube_size (tuple): Dimensions of the cube (dx, dy, dz).\n",
    "\n",
    "    Returns:\n",
    "        float: The ADev metric.\n",
    "    \"\"\"\n",
    "    # Define the cube grid based on the range of the data and cube size\n",
    "    min_coords = np.min(np.vstack((predictions, targets)), axis=0)\n",
    "    max_coords = np.max(np.vstack((predictions, targets)), axis=0)\n",
    "\n",
    "    # Create a grid of cubes\n",
    "    grid_shape = ((max_coords - min_coords) / cube_size).astype(int) + 1\n",
    "\n",
    "    # Initialize the cube occupancy arrays\n",
    "    pred_cubes = np.zeros(grid_shape, dtype=int)\n",
    "    target_cubes = np.zeros(grid_shape, dtype=int)\n",
    "\n",
    "    # Map trajectories to cubes\n",
    "    pred_indices = ((predictions - min_coords) / cube_size).astype(int)\n",
    "    target_indices = ((targets - min_coords) / cube_size).astype(int)\n",
    "\n",
    "    # Mark cubes visited by predictions and targets\n",
    "    for idx in pred_indices:\n",
    "        pred_cubes[tuple(idx)] = 1\n",
    "    for idx in target_indices:\n",
    "        target_cubes[tuple(idx)] = 1\n",
    "\n",
    "    # Compute the ADev metric\n",
    "    adev = np.sum(np.abs(pred_cubes - target_cubes))\n",
    "    return adev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643beaa",
   "metadata": {},
   "source": [
    "## TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27eb2fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 6330\n"
     ]
    }
   ],
   "source": [
    "class TCNBaseline3D(nn.Module):\n",
    "    \"\"\"\n",
    "    2-layer causal TCN       (kernel=3, dilation=1 & 2, padding chosen\n",
    "    so receptive field = 5 time-steps).\n",
    "    ----------------------\n",
    "    • input_dim  = 3\n",
    "    • hidden_dim = 32  → total ≈ 4.9 k parameters\n",
    "    • output_dim = 3    (one-step prediction)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_dim:  int = 3,\n",
    "                 hidden_dim: int = 32,\n",
    "                 output_dim: int = 3,\n",
    "                 lr: float = 1e-3,\n",
    "                 epochs: int = 40,\n",
    "                 device: str = \"cpu\",\n",
    "                 seed: int = 0):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(seed); np.random.seed(seed)\n",
    "\n",
    "        k = 3  # kernel\n",
    "        # layer 1: dilation 1  → pad 2 to keep length\n",
    "        self.conv1 = nn.Conv1d(input_dim, hidden_dim,\n",
    "                               kernel_size=k,\n",
    "                               dilation=1,\n",
    "                               padding=2,\n",
    "                               bias=True)\n",
    "        # layer 2: dilation 2  → pad 4\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim,\n",
    "                               kernel_size=k,\n",
    "                               dilation=2,\n",
    "                               padding=4,\n",
    "                               bias=True)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.head  = nn.Conv1d(hidden_dim, output_dim,\n",
    "                               kernel_size=1, bias=True)\n",
    "\n",
    "        self.lr, self.epochs = lr, epochs\n",
    "        self.to(device)\n",
    "        self.optim = Adam(self.parameters(), lr=lr)\n",
    "        self.crit  = nn.MSELoss()\n",
    "        \n",
    "    def total_parameters(self):\n",
    "        total = 0\n",
    "        for param in list(self.model.parameters()) + list(self.head.parameters()):\n",
    "            total += param.numel()\n",
    "        return total\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape  [B, T, 3]  (batch, time, channels)\n",
    "        return  [B, T, 3]\n",
    "        \"\"\"\n",
    "        # reshape to Conv1d convention: (B, C, T)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        y = self.conv1(x); y = self.relu(y[:, :, :-2])     # remove look-ahead pad\n",
    "        y = self.conv2(y); y = self.relu(y[:, :, :-4])     # remove look-ahead pad\n",
    "        out = self.head(y).permute(0, 2, 1)                # back to (B,T,C)\n",
    "        return out\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    def fit(self, x_np: np.ndarray, y_np: np.ndarray):\n",
    "        \"\"\"\n",
    "        Teacher-forcing on entire sequence (batch size = 1).\n",
    "        x_np, y_np shape [T, 3]\n",
    "        \"\"\"\n",
    "        x = torch.tensor(x_np[None], dtype=torch.float32, device=next(self.parameters()).device)\n",
    "        y = torch.tensor(y_np[None], dtype=torch.float32, device=next(self.parameters()).device)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            self.optim.zero_grad()\n",
    "            pred = self.forward(x)\n",
    "            loss = self.crit(pred[:, :-1], y[:, 1:])  # predict next step\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    @torch.no_grad()\n",
    "    def predict(self, init_window: np.ndarray, n_steps: int):\n",
    "        \"\"\"\n",
    "        Autoregressive roll-out.\n",
    "        init_window : length L≥5, shape [L,3] (latest samples, earliest first)\n",
    "        Returns      : [n_steps,3]\n",
    "        \"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        window = init_window.copy()\n",
    "        preds  = np.empty((n_steps, 3), dtype=np.float32)\n",
    "\n",
    "        for t in range(n_steps):\n",
    "            inp = torch.tensor(window[None], dtype=torch.float32, device=device)\n",
    "            y   = self.forward(inp)[0, -1].cpu().numpy()\n",
    "            preds[t] = y\n",
    "            window   = np.vstack([window[1:], y])  # slide window\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_open_loop(self, x_np: np.ndarray):\n",
    "        \"\"\"\n",
    "        Open-loop prediction (teacher-forced inputs).\n",
    "        x_np shape: [T, 3]\n",
    "        Returns:\n",
    "            preds: [T - 1, 3] – one-step-ahead predictions\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        x = torch.tensor(x_np[None], dtype=torch.float32, device=device)  # [1, T, 3]\n",
    "        preds = self.forward(x)  # [1, T, 3]\n",
    "        preds = preds[:, :-1]    # predict from t=0 to t=T-2 for target t=1 to t=T-1\n",
    "\n",
    "        return preds.squeeze(0).cpu().numpy()\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = LSTMBaseline3D()\n",
    "    print(f\"Total trainable parameters: {model.total_parameters()}\")\n",
    "\n",
    "\n",
    "# tcn = TCNBaseline3D(hidden_dim=32, epochs=50, lr=1e-3, device=\"cpu\", seed=46)\n",
    "# tcn.fit(train_input, train_target)\n",
    "\n",
    "# # initial window must be >4 samples:\n",
    "# init_win = test_input[:5].copy()\n",
    "# tcn_preds = tcn.predict(init_win, n_steps=len(test_target))\n",
    "# tcn_preds_open_loop = tcn.predict_open_loop(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58809d1",
   "metadata": {},
   "source": [
    "### Canonical Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "578f4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_deriv(state, t, sigma=10.0, rho=28.0, beta=8.0/3.0):\n",
    "    x, y, z = state\n",
    "    dxdt = sigma * (y - x)\n",
    "    dydt = x*(rho - z) - y\n",
    "    dzdt = x*y - beta*z\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_lorenz_data(\n",
    "    initial_state=[1.0, 1.0, 1.0],\n",
    "    tmax=25.0,\n",
    "    dt=0.01,\n",
    "    sigma=10.0,\n",
    "    rho=28.0,\n",
    "    beta=8.0/3.0\n",
    "):\n",
    "    num_steps = int(tmax / dt) + 1 # +1 to include t=0\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(lorenz_deriv, initial_state, t_vals, args=(sigma, rho, beta))\n",
    "    return t_vals, sol\n",
    "\n",
    "def rossler_derivatives(state, t, a=0.2, b=0.2, c=5.7):\n",
    "    \"\"\"Compute time derivatives [dx/dt, dy/dt, dz/dt] for the Rössler system.\"\"\"\n",
    "    x, y, z = state\n",
    "    dxdt = -y - z\n",
    "    dydt = x + a * y\n",
    "    dzdt = b + z * (x - c)\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_rossler_data(\n",
    "    initial_state=[1.0, 0.0, 0.0],\n",
    "    tmax=25.0,\n",
    "    dt=0.01,\n",
    "    a=0.2,\n",
    "    b=0.2,\n",
    "    c=5.7\n",
    "):\n",
    "    \"\"\"\n",
    "    Numerically integrate Rössler equations x'(t), y'(t), z'(t) using odeint.\n",
    "    Returns:\n",
    "       t_vals: array of time points\n",
    "       sol   : array shape [num_steps, 3] of [x(t), y(t), z(t)]\n",
    "    \"\"\"\n",
    "    num_steps = int(tmax / dt)\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(rossler_derivatives, initial_state, t_vals, args=(a, b, c))\n",
    "    return t_vals, sol\n",
    "\n",
    "def chen_deriv(state, t, a=35.0, b=3.0, c=28.0):\n",
    "    \"\"\"\n",
    "    Computes derivatives [dx/dt, dy/dt, dz/dt] for Chen system:\n",
    "      dx/dt = a*(y - x)\n",
    "      dy/dt = (c - a)*x + c*y - x*z\n",
    "      dz/dt = x*y - b*z\n",
    "    \"\"\"\n",
    "    x, y, z = state\n",
    "    dxdt = a*(y - x)\n",
    "    dydt = (c - a)*x + c*y - x*z\n",
    "    dzdt = x*y - b*z\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_chen_data(\n",
    "    initial_state=[1.0, 1.0, 1.0],\n",
    "    tmax=50.0,\n",
    "    dt=0.01,\n",
    "    a=35.0,\n",
    "    b=3.0,\n",
    "    c=28.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Integrates Chen's system from 'initial_state' up to time 'tmax' with step size 'dt'.\n",
    "    Returns:\n",
    "      t_vals: time array of length T\n",
    "      sol   : array shape [T, 3], the trajectory [x(t), y(t), z(t)]\n",
    "    \"\"\"\n",
    "    num_steps = int(tmax / dt)\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(chen_deriv, initial_state, t_vals, args=(a, b, c))\n",
    "    return t_vals, sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8089a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"input_dim\": [3],\n",
    "    \"hidden_size\": [37],\n",
    "    \"output_dim\": [3],\n",
    "    \"lr\": [1e-3],\n",
    "    \"epochs\": [50],\n",
    "    \"device\": ['cuda'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b326ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(model_class, param_grid, model_name,\n",
    "                    output_path=\"grid_search_results.json\", f=generate_chen_data, lambda_max=0.9):\n",
    "    combos = list(itertools.product(*param_grid.values()))\n",
    "    param_keys = list(param_grid.keys())\n",
    "    print(f\"\\n== Initial grid search for {model_name} with {len(combos)} combinations ==\")\n",
    "\n",
    "    results = []\n",
    "    # horizons = list(range(10, 1001, 10))\n",
    "    horizons = [200, 400, 600, 800, 1000]\n",
    "    \n",
    "\n",
    "    for comb in tqdm(combos, desc=\"Grid Search\"):\n",
    "        params = dict(zip(param_keys, comb))\n",
    "        # seed_scores_vpt = []\n",
    "        horizon_nrmse_all = {h: [] for h in horizons}\n",
    "        # adev_scores = []\n",
    "        # ldev_scores = []\n",
    "\n",
    "        for initial_state in [[1.0, 1.0, 1.0], [1.0, 2.0, 3.0], [2.0, 1.5, 4.0]]:\n",
    "            tmax = 250\n",
    "            dt = 0.02\n",
    "            t_vals, lorenz_traj = f(\n",
    "                initial_state=initial_state,\n",
    "                tmax=tmax,\n",
    "                dt=dt\n",
    "            )\n",
    "\n",
    "            washout = 2000\n",
    "            t_vals = t_vals[washout:]\n",
    "            lorenz_traj = lorenz_traj[washout:]\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(lorenz_traj)\n",
    "            lorenz_traj = scaler.transform(lorenz_traj)\n",
    "\n",
    "            T_data = len(lorenz_traj)\n",
    "            for train_frac in [0.7, 0.75, 0.8]:\n",
    "                train_end = int(train_frac * (T_data - 1))\n",
    "                train_input = lorenz_traj[:train_end]\n",
    "                train_target = lorenz_traj[1:train_end + 1]\n",
    "                test_input = lorenz_traj[train_end:-1]\n",
    "                test_target = lorenz_traj[train_end + 1:]\n",
    "                n_test_steps = len(test_input)\n",
    "                initial_in = test_input[0]\n",
    "\n",
    "                for seed in np.arange(1, 5):\n",
    "                    model = model_class(**params, seed=seed)\n",
    "                    model.fit(train_input, train_target)\n",
    "                    preds = model.predict(initial_in, n_test_steps)\n",
    "\n",
    "                    # T_VPT_s, _, ratio = compute_valid_prediction_time(test_target, preds, t_vals, 0.4, lambda_max, dt)\n",
    "                    # seed_scores_vpt.append(ratio)\n",
    "\n",
    "                    horizon_nrmse = evaluate_nrmse(preds, test_target, horizons)\n",
    "                    for h in horizons:\n",
    "                        horizon_nrmse_all[h].append(horizon_nrmse[h])\n",
    "\n",
    "                    # adev = compute_attractor_deviation(preds, test_target)\n",
    "                    # adev_scores.append(adev)\n",
    "\n",
    "                    # ldev = compute_lyapunov_exponent(\"Lorenz\", preds, dt)\n",
    "                    # ldev_scores.append(ldev)\n",
    "\n",
    "        # mean_vpt = float(np.mean(seed_scores_vpt))\n",
    "        # std_vpt = float(np.std(seed_scores_vpt))\n",
    "        mean_nrmse_dict = {str(h): float(np.mean(horizon_nrmse_all[h])) for h in horizons}\n",
    "        std_nrmse_dict  = {str(h): float(np.std(horizon_nrmse_all[h]))  for h in horizons}\n",
    "        # mean_adev = float(np.mean(adev_scores))\n",
    "        # std_adev = float(np.std(adev_scores))\n",
    "        # mean_ldev = float(np.mean(ldev_scores))\n",
    "        # std_ldev = float(np.std(ldev_scores))\n",
    "\n",
    "        results.append({\n",
    "            \"params\": params,\n",
    "            # \"seed_scores_T_VPT\": seed_scores_vpt,\n",
    "            # \"mean_T_VPT\": mean_vpt,\n",
    "            # \"std_T_VPT\": std_vpt,\n",
    "            \"mean_NRMSEs\": mean_nrmse_dict,\n",
    "            \"std_NRMSEs\": std_nrmse_dict,\n",
    "            # \"mean_ADev\": mean_adev,\n",
    "            # \"std_ADev\": std_adev,\n",
    "            # \"mean_LDev\": mean_ldev,\n",
    "            # \"std_LDev\": std_ldev\n",
    "        })\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"\\nAll results saved to `{output_path}`\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "569374f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Initial grid search for lstm with 1 combinations ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search: 100%|██████████| 1/1 [00:42<00:00, 42.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All results saved to `lstm.json`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'params': {'input_dim': 3,\n",
       "   'hidden_size': 37,\n",
       "   'output_dim': 3,\n",
       "   'lr': 0.001,\n",
       "   'epochs': 50,\n",
       "   'device': 'cuda'},\n",
       "  'mean_NRMSEs': {'200': 1.1498553747982223,\n",
       "   '400': 1.1106524375085538,\n",
       "   '600': 1.1055218707096879,\n",
       "   '800': 1.1042270550905167,\n",
       "   '1000': 1.098894237887603},\n",
       "  'std_NRMSEs': {'200': 0.08139917303893686,\n",
       "   '400': 0.05698845168499877,\n",
       "   '600': 0.05411126447914175,\n",
       "   '800': 0.05169483255488391,\n",
       "   '1000': 0.050448357124515245}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_grid_search(LSTMBaseline3D, grid, \"lstm\", output_path=\"lstm.json\", f=generate_chen_data, lambda_max=0.829)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef374033",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"input_dim\": [3],\n",
    "    \"hidden_dim\": [32],\n",
    "    \"output_dim\": [3],\n",
    "    \"lr\": [1e-3],\n",
    "    \"epochs\": [50],\n",
    "    \"device\": ['cuda'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "028111d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_grid_search(TCNBaseline3D, grid, \"tcn\", output_path=\"tcn.json\", f=generate_lorenz_data, lambda_max=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b20cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
