{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fdede0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:16.055576Z",
     "iopub.status.busy": "2025-08-02T12:15:16.055317Z",
     "iopub.status.idle": "2025-08-02T12:15:21.957181Z",
     "shell.execute_reply": "2025-08-02T12:15:21.956581Z",
     "shell.execute_reply.started": "2025-08-02T12:15:16.055555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.linear_model import Ridge\n",
    "from matplotlib.colors import Normalize\n",
    "import networkx as nx\n",
    "from scipy.signal import welch\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52baae13",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9b6f5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:21.959001Z",
     "iopub.status.busy": "2025-08-02T12:15:21.958561Z",
     "iopub.status.idle": "2025-08-02T12:15:24.598228Z",
     "shell.execute_reply": "2025-08-02T12:15:24.597570Z",
     "shell.execute_reply.started": "2025-08-02T12:15:21.958980Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 6330\n"
     ]
    }
   ],
   "source": [
    "class LSTMBaseline3D:\n",
    "    \"\"\"\n",
    "    Lightweight single-layer LSTM for 3-dim Lorenz forecasting.\n",
    "    * hidden_size=32 → ~4.8k trainable parameters\n",
    "    * fit() trains in teacher-forcing mode\n",
    "    * predict() produces autoregressive roll-out\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim:  int = 3,\n",
    "                 hidden_size: int = 37,\n",
    "                 output_dim: int = 3,\n",
    "                 lr: float = 1e-3,\n",
    "                 epochs: int = 30,\n",
    "                 device: str = 'cpu',\n",
    "                 seed: int = 0):\n",
    "        torch.manual_seed(seed); np.random.seed(seed)\n",
    "\n",
    "        self.device  = torch.device(device)\n",
    "        self.epochs  = epochs\n",
    "        self.model   = nn.LSTM(input_dim, hidden_size,\n",
    "                               batch_first=True).to(self.device)\n",
    "        self.head    = nn.Linear(hidden_size, output_dim).to(self.device)\n",
    "        self.crit    = nn.MSELoss()\n",
    "        self.optim   = Adam(list(self.model.parameters())+\n",
    "                            list(self.head.parameters()), lr=lr)\n",
    "        \n",
    "    def total_parameters(self):\n",
    "        total = 0\n",
    "        for param in list(self.model.parameters()) + list(self.head.parameters()):\n",
    "            total += param.numel()\n",
    "        return total\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    @torch.no_grad()\n",
    "    def _init_hidden(self, batch_sz=1):\n",
    "        h0 = torch.zeros(1, batch_sz,\n",
    "                         self.model.hidden_size,\n",
    "                         device=self.device)\n",
    "        c0 = torch.zeros_like(h0)\n",
    "        return (h0, c0)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    def fit(self, x_np: np.ndarray, y_np: np.ndarray):\n",
    "        \"\"\"\n",
    "        x_np shape [T, 3]  (input  at t)\n",
    "        y_np shape [T, 3]  (target at t)\n",
    "        \"\"\"\n",
    "        x = torch.tensor(x_np, dtype=torch.float32,\n",
    "                         device=self.device).unsqueeze(0)  # [1,T,3]\n",
    "        y = torch.tensor(y_np, dtype=torch.float32,\n",
    "                         device=self.device).unsqueeze(0)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            self.optim.zero_grad()\n",
    "            out, _ = self.model(x, self._init_hidden())\n",
    "            pred   = self.head(out)\n",
    "            loss   = self.crit(pred, y)\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    @torch.no_grad()\n",
    "    def predict(self, init_u: np.ndarray, n_steps: int):\n",
    "        \"\"\"\n",
    "        Autoregressive roll-out.\n",
    "        init_u : initial 3-vector (last known sample)\n",
    "        Returns array of shape [n_steps, 3].\n",
    "        \"\"\"\n",
    "        self.model.eval(); self.head.eval()\n",
    "\n",
    "        inp     = torch.tensor(init_u[None, None, :],\n",
    "                               dtype=torch.float32, device=self.device)\n",
    "        h, c    = self._init_hidden()\n",
    "        preds   = np.empty((n_steps, 3), dtype=np.float32)\n",
    "\n",
    "        for t in range(n_steps):\n",
    "            out, (h, c) = self.model(inp, (h, c))\n",
    "            y           = self.head(out)\n",
    "            preds[t]    = y.squeeze(0).cpu().numpy()\n",
    "            inp         = y.detach()    # feed prediction back\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_open_loop(self, x_np: np.ndarray):\n",
    "        \"\"\"\n",
    "        Open-loop prediction using teacher-forced inputs (like during training).\n",
    "        x_np shape: [T, 3] – input sequence\n",
    "        Returns:\n",
    "            preds: [T, 3] – predicted output sequence\n",
    "        \"\"\"\n",
    "        self.model.eval(); self.head.eval()\n",
    "\n",
    "        x = torch.tensor(x_np, dtype=torch.float32,\n",
    "                         device=self.device).unsqueeze(0)  # [1, T, 3]\n",
    "        out, _ = self.model(x, self._init_hidden())\n",
    "        preds = self.head(out).squeeze(0).cpu().numpy()  # [T, 3]\n",
    "\n",
    "        return preds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = LSTMBaseline3D()\n",
    "    print(f\"Total trainable parameters: {model.total_parameters()}\")\n",
    "\n",
    "# lstm_baseline = LSTMBaseline3D(\n",
    "#                     hidden_size=38,         # parameter budget ~ 4800\n",
    "#                     lr=1e-3,\n",
    "#                     epochs=100,\n",
    "#                     device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "#                     seed=45)\n",
    "# lstm_baseline.fit(train_input, train_target)\n",
    "\n",
    "# # one-step roll-out to build an initial vector for auto-regressive mode\n",
    "# init_vec = train_target[-1]                # last teacher-forced target\n",
    "# lstm_preds = lstm_baseline.predict(init_vec,\n",
    "#                                    n_steps=len(test_input))\n",
    "# lstm_preds_open_loop = lstm_baseline.predict_open_loop(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "011886ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.599388Z",
     "iopub.status.busy": "2025-08-02T12:15:24.598949Z",
     "iopub.status.idle": "2025-08-02T12:15:24.627295Z",
     "shell.execute_reply": "2025-08-02T12:15:24.626575Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.599369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TCNBaseline3D(nn.Module):\n",
    "    \"\"\"\n",
    "    2-layer causal TCN       (kernel=3, dilation=1 & 2, padding chosen\n",
    "    so receptive field = 5 time-steps, identical to NVAR window length).\n",
    "    ----------------------\n",
    "    • input_dim  = 3\n",
    "    • hidden_dim = 32  → total ≈ 4.9 k parameters\n",
    "    • output_dim = 3    (one-step prediction)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_dim:  int = 3,\n",
    "                 hidden_dim: int = 32,\n",
    "                 output_dim: int = 3,\n",
    "                 lr: float = 1e-3,\n",
    "                 epochs: int = 40,\n",
    "                 device: str = \"cpu\",\n",
    "                 seed: int = 0):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(seed); np.random.seed(seed)\n",
    "\n",
    "        k = 3  # kernel\n",
    "        # layer 1: dilation 1  → pad 2 to keep length\n",
    "        self.conv1 = nn.Conv1d(input_dim, hidden_dim,\n",
    "                               kernel_size=k,\n",
    "                               dilation=1,\n",
    "                               padding=2,\n",
    "                               bias=True)\n",
    "        # layer 2: dilation 2  → pad 4\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim,\n",
    "                               kernel_size=k,\n",
    "                               dilation=2,\n",
    "                               padding=4,\n",
    "                               bias=True)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.head  = nn.Conv1d(hidden_dim, output_dim,\n",
    "                               kernel_size=1, bias=True)\n",
    "\n",
    "        self.lr, self.epochs = lr, epochs\n",
    "        self.to(device)\n",
    "        self.optim = Adam(self.parameters(), lr=lr)\n",
    "        self.crit  = nn.MSELoss()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape  [B, T, 3]  (batch, time, channels)\n",
    "        return  [B, T, 3]\n",
    "        \"\"\"\n",
    "        # reshape to Conv1d convention: (B, C, T)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        y = self.conv1(x); y = self.relu(y[:, :, :-2])     # remove look-ahead pad\n",
    "        y = self.conv2(y); y = self.relu(y[:, :, :-4])     # remove look-ahead pad\n",
    "        out = self.head(y).permute(0, 2, 1)                # back to (B,T,C)\n",
    "        return out\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    def fit(self, x_np: np.ndarray, y_np: np.ndarray):\n",
    "        \"\"\"\n",
    "        Teacher-forcing on entire sequence (batch size = 1).\n",
    "        x_np, y_np shape [T, 3]\n",
    "        \"\"\"\n",
    "        x = torch.tensor(x_np[None], dtype=torch.float32, device=next(self.parameters()).device)\n",
    "        y = torch.tensor(y_np[None], dtype=torch.float32, device=next(self.parameters()).device)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            self.optim.zero_grad()\n",
    "            pred = self.forward(x)\n",
    "            loss = self.crit(pred[:, :-1], y[:, 1:])  # predict next step\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    @torch.no_grad()\n",
    "    def predict(self, init_window: np.ndarray, n_steps: int):\n",
    "        \"\"\"\n",
    "        Autoregressive roll-out.\n",
    "        init_window : length L≥5, shape [L,3] (latest samples, earliest first)\n",
    "        Returns      : [n_steps,3]\n",
    "        \"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        window = init_window.copy()\n",
    "        preds  = np.empty((n_steps, 3), dtype=np.float32)\n",
    "\n",
    "        for t in range(n_steps):\n",
    "            inp = torch.tensor(window[None], dtype=torch.float32, device=device)\n",
    "            y   = self.forward(inp)[0, -1].cpu().numpy()\n",
    "            preds[t] = y\n",
    "            window   = np.vstack([window[1:], y])  # slide window\n",
    "\n",
    "        return preds\n",
    "\n",
    "\n",
    "# tcn = TCNBaseline3D(hidden_dim=32, epochs=50, lr=1e-3, device=\"cpu\", seed=46)\n",
    "# tcn.fit(train_input, train_target)\n",
    "\n",
    "# # initial window must be ≥5 samples:\n",
    "# init_win = test_input[:5].copy()\n",
    "# tcn_preds = tcn.predict(init_win, n_steps=len(test_target))\n",
    "\n",
    "# ============================================================\n",
    "#  Causal Transformer baseline for 3-D Lorenz forecasting\n",
    "#  (PyTorch ≥ 1.9)\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "class SmallCausalTransformer3D(nn.Module):\n",
    "    \"\"\"\n",
    "    Single-layer causal Transformer:\n",
    "      • d_model = 24,   nhead = 1,   d_ff = 4·d_model\n",
    "      • receptive field  = sequence length L (set in fit / predict)\n",
    "      • total parameters ≈ 4 900\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 d_model: int = 24,\n",
    "                 nhead: int = 1,\n",
    "                 d_ff: int = 96,        # 4 × d_model\n",
    "                 lr: float = 2e-3,\n",
    "                 epochs: int = 60,\n",
    "                 device: str = \"cpu\",\n",
    "                 seed: int = 0):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(seed); np.random.seed(seed)\n",
    "        self.device, self.epochs = device, epochs\n",
    "\n",
    "        self.in_proj   = nn.Linear(3, d_model)     # 3-dim input → tokens\n",
    "        encoder_layer  = nn.TransformerEncoderLayer(\n",
    "                             d_model=d_model,\n",
    "                             nhead=nhead,\n",
    "                             dim_feedforward=d_ff,\n",
    "                             batch_first=True,\n",
    "                             activation=\"gelu\",\n",
    "                             norm_first=True)\n",
    "        self.encoder   = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "        self.pos_embed = None                      # built on first call\n",
    "        self.head      = nn.Linear(d_model, 3)     # back to 3-dim output\n",
    "\n",
    "        self.to(device)\n",
    "        self.opt  = Adam(self.parameters(), lr=lr)\n",
    "        self.crit = nn.MSELoss()\n",
    "\n",
    "    # ----------------------------------------\n",
    "    def _get_posembed(self, L: int, d: int):\n",
    "        \"\"\"Fixed sinusoidal positional embedding (same as Vaswani et al.).\"\"\"\n",
    "        pos = torch.arange(L, dtype=torch.float32, device=self.device)\n",
    "        i   = torch.arange(d//2, dtype=torch.float32, device=self.device)\n",
    "        angles = pos[:, None] / (10000 ** (2*i/d))\n",
    "        pe = torch.zeros(L, d, device=self.device)\n",
    "        pe[:, 0::2] = torch.sin(angles)\n",
    "        pe[:, 1::2] = torch.cos(angles)\n",
    "        return pe[None]                                # shape (1,L,d)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    def fit(self, x_np: np.ndarray, y_np: np.ndarray, L: int = 20):\n",
    "        \"\"\"\n",
    "        Teacher-forcing with sliding windows of length L.\n",
    "        x_np, y_np  shape [T, 3];  y_np[t] is the desired prediction for x_np[t].\n",
    "        \"\"\"\n",
    "        x = torch.tensor(x_np, dtype=torch.float32, device=self.device)\n",
    "        y = torch.tensor(y_np, dtype=torch.float32, device=self.device)\n",
    "\n",
    "        if self.pos_embed is None or self.pos_embed.size(1) != L:\n",
    "            self.pos_embed = self._get_posembed(L, self.in_proj.out_features)\n",
    "\n",
    "        # build training batches as overlapping windows (stride 1)\n",
    "        windows   = x.unfold(0, L, 1)        # shape [T-L+1, L, 3]\n",
    "        targets   = y[L-1:]                  # predict the last step\n",
    "        dataset   = torch.utils.data.TensorDataset(windows, targets)\n",
    "        loader    = torch.utils.data.DataLoader(dataset,\n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            for batch_x, batch_y in loader:\n",
    "                self.opt.zero_grad()\n",
    "                z   = self.in_proj(batch_x) + self.pos_embed\n",
    "                out = self.encoder(z)\n",
    "                pred = self.head(out[:, -1])          # last token\n",
    "                loss = self.crit(pred, batch_y)\n",
    "                loss.backward(); self.opt.step()\n",
    "\n",
    "    # ----------------------------------------\n",
    "    @torch.no_grad()\n",
    "    def predict(self, init_window: np.ndarray, n_steps: int):\n",
    "        \"\"\"\n",
    "        Autoregressive roll-out.\n",
    "        init_window : numpy (L,3)  – most recent L samples (old → new)\n",
    "        Returns      : numpy (n_steps,3)\n",
    "        \"\"\"\n",
    "        L = init_window.shape[0]\n",
    "        if self.pos_embed is None or self.pos_embed.size(1) != L:\n",
    "            self.pos_embed = self._get_posembed(L, self.in_proj.out_features)\n",
    "\n",
    "        window = torch.tensor(init_window, dtype=torch.float32,\n",
    "                              device=self.device)\n",
    "        preds  = np.empty((n_steps, 3), dtype=np.float32)\n",
    "\n",
    "        for t in range(n_steps):\n",
    "            z   = self.in_proj(window[None]) + self.pos_embed\n",
    "            y   = self.head(self.encoder(z)[:, -1])[0]\n",
    "            preds[t] = y.cpu().numpy()\n",
    "\n",
    "            window = torch.vstack([window[1:], y])\n",
    "\n",
    "        return preds\n",
    "\n",
    "# # ---------------------------------------------------\n",
    "# #  hyper-parameters chosen to match ≈ 5 k weights\n",
    "# # ---------------------------------------------------\n",
    "# tformer = SmallCausalTransformer3D(d_model=24,\n",
    "#                                    d_ff=96,\n",
    "#                                    epochs=60,\n",
    "#                                    lr=2e-3,\n",
    "#                                    device=\"cpu\",\n",
    "#                                    seed=47)\n",
    "\n",
    "# seq_len = 20                         # receptive field (same as NVAR window)\n",
    "# tformer.fit(train_input, train_target, L=seq_len)\n",
    "\n",
    "# init_win = test_input[:seq_len].copy()\n",
    "# tf_preds = tformer.predict(init_win, n_steps=len(test_target))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  Non-linear Vector Auto-Regression (NVAR) baseline for 3-D Lorenz\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "from itertools import combinations_with_replacement\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "class NVARBaseline3D:\n",
    "    \"\"\"\n",
    "    • delay window length k   (default 5 samples)\n",
    "    • quadratic polynomial lift (all monomials up to degree 2)\n",
    "    • closed-form ridge regression read-out\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 k: int = 5,\n",
    "                 ridge_alpha: float = 1e-4):\n",
    "        self.k          = k\n",
    "        self.alpha      = ridge_alpha\n",
    "        self.scaler_mu  = None\n",
    "        self.scaler_sig = None\n",
    "        self.reg        = Ridge(alpha=self.alpha, fit_intercept=False)\n",
    "\n",
    "        # indices for quadratic terms\n",
    "        L  = 3 * k                 # length of flattened delay vector\n",
    "        self.idxs_quad = list(combinations_with_replacement(range(L), 2))\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    def _build_feature(self, window: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        window: shape (k, 3)  -> returns (F,) where\n",
    "          F = 1 + 3k + (3k)(3k+1)/2\n",
    "        \"\"\"\n",
    "        lin = window.flatten()                 # linear terms\n",
    "        quad = np.array([lin[i]*lin[j] for i, j in self.idxs_quad])\n",
    "        return np.concatenate(([1.0], lin, quad), dtype=np.float32)\n",
    "    \n",
    "    def total_parameters(self):\n",
    "        total = 0\n",
    "        for param in list(self.model.parameters()) + list(self.head.parameters()):\n",
    "            total += param.numel()\n",
    "        return total\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    def fit(self, x_np: np.ndarray, y_np: np.ndarray):\n",
    "        \"\"\"\n",
    "        x_np shape [T, 3] (driver)\n",
    "        y_np shape [T, 3] (target 1-step ahead)\n",
    "        Assumes x_np[t] predicts y_np[t].\n",
    "        \"\"\"\n",
    "        k = self.k\n",
    "        assert len(x_np) == len(y_np)\n",
    "        # normalise inputs\n",
    "        self.scaler_mu  = x_np.mean(0, keepdims=True)\n",
    "        self.scaler_sig = x_np.std (0, keepdims=True) + 1e-9\n",
    "        x_norm = (x_np - self.scaler_mu)/self.scaler_sig\n",
    "\n",
    "        feats, targets = [], []\n",
    "        for t in range(k, len(x_norm)):\n",
    "            window = x_norm[t-k:t]              # shape (k,3)\n",
    "            feats.append(self._build_feature(window))\n",
    "            targets.append(y_np[t])\n",
    "\n",
    "        X = np.vstack(feats)\n",
    "        Y = np.vstack(targets)\n",
    "        self.reg.fit(X, Y)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    def predict(self, init_window: np.ndarray, n_steps: int):\n",
    "        \"\"\"\n",
    "        Autoregressive roll-out.\n",
    "        init_window : array (k,3)  – most recent k inputs (y-values).\n",
    "        Returns array (n_steps,3)\n",
    "        \"\"\"\n",
    "        k = self.k\n",
    "        window = init_window.copy()\n",
    "        preds  = np.empty((n_steps, 3), dtype=np.float32)\n",
    "\n",
    "        for t in range(n_steps):\n",
    "            w_norm  = (window - self.scaler_mu)/self.scaler_sig\n",
    "            phi     = self._build_feature(w_norm)\n",
    "            y_hat   = self.reg.predict(phi[None, :])[0]\n",
    "            preds[t] = y_hat\n",
    "            # slide window: drop oldest, append new prediction\n",
    "            window = np.vstack([window[1:], y_hat])\n",
    "\n",
    "        return preds\n",
    "\n",
    "# # ---------------------------------------------------\n",
    "# #  create training windows  (same split as before)\n",
    "# # ---------------------------------------------------\n",
    "# k = 5\n",
    "# nvar = NVARBaseline3D(k=k, ridge_alpha=1e-4)\n",
    "# nvar.fit(train_input, train_target)\n",
    "\n",
    "# # prepare the last k samples as initial window\n",
    "# init_window = test_input[:k].copy()\n",
    "# nvar_preds  = nvar.predict(init_window, n_steps=len(test_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878d0f3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.628322Z",
     "iopub.status.busy": "2025-08-02T12:15:24.628119Z",
     "iopub.status.idle": "2025-08-02T12:15:24.666708Z",
     "shell.execute_reply": "2025-08-02T12:15:24.665953Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.628307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_nrmse(all_preds, test_target, horizons):\n",
    "    \"\"\"\n",
    "    Evaluate model performance over multiple prediction horizons\n",
    "    for teacher-forced single-step forecasting or autoregressive rollout.\n",
    "    \"\"\"\n",
    "    horizon_nrmse = {}\n",
    "    for horizon in horizons:\n",
    "        preds = all_preds[:horizon]\n",
    "        targets = test_target[:horizon]\n",
    "        squared_errors = (preds - targets) ** 2\n",
    "        variance = np.var(targets, axis=0)\n",
    "        variance[variance == 0] = 1e-8  # avoid divide-by-zero\n",
    "        nrmse = np.sqrt(np.sum(squared_errors) / (horizon * np.sum(variance)))\n",
    "        horizon_nrmse[horizon] = nrmse\n",
    "    return horizon_nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a6add6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.668875Z",
     "iopub.status.busy": "2025-08-02T12:15:24.668636Z",
     "iopub.status.idle": "2025-08-02T12:15:24.685537Z",
     "shell.execute_reply": "2025-08-02T12:15:24.684853Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.668854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_valid_prediction_time(y_true, y_pred, t_vals, threshold, lambda_max, dt):\n",
    "    \"\"\"\n",
    "    Compute the Valid Prediction Time (VPT) and compare it to Lyapunov time T_lambda = 1 / lambda_max.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : ndarray of shape (N, dim)\n",
    "        True trajectory over time.\n",
    "    y_pred : ndarray of shape (N, dim)\n",
    "        Model's predicted trajectory over time (closed-loop).\n",
    "    t_vals : ndarray of shape (N,)\n",
    "        Time values corresponding to the trajectory steps.\n",
    "    threshold : float, optional\n",
    "        The error threshold, default is 0.4 as in your snippet.\n",
    "    lambda_max : float, optional\n",
    "        Largest Lyapunov exponent. Default=0.9 for Lorenz.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    T_VPT : float\n",
    "        Valid prediction time. The earliest time at which normalized error surpasses threshold\n",
    "        (or the last time if never surpassed).\n",
    "    T_lambda : float\n",
    "        Lyapunov time = 1 / lambda_max\n",
    "    ratio : float\n",
    "        How many Lyapunov times the model prediction remains valid, i.e. T_VPT / T_lambda.\n",
    "    \"\"\"\n",
    "    # 1) Average of y_true\n",
    "    y_mean = np.mean(y_true, axis=0)  # shape (dim,)\n",
    "    \n",
    "    # 2) Time-averaged norm^2 of (y_true - y_mean)\n",
    "    y_centered = y_true - y_mean\n",
    "    denom = np.mean(np.sum(y_centered**2, axis=1))  # scalar\n",
    "    \n",
    "    # 3) Compute the normalized error delta_gamma(t) = ||y_true - y_pred||^2 / denom\n",
    "    diff = y_true - y_pred\n",
    "    err_sq = np.sum(diff**2, axis=1)  # shape (N,)\n",
    "    delta_gamma = err_sq / denom      # shape (N,)\n",
    "    \n",
    "    # 4) Find the first time index where delta_gamma(t) exceeds threshold\n",
    "    idx_exceed = np.where(delta_gamma > threshold)[0]\n",
    "    if len(idx_exceed) == 0:\n",
    "        # never exceeds threshold => set T_VPT to the final time\n",
    "        T_VPT = t_vals[-1]\n",
    "    else:\n",
    "        T_VPT = t_vals[idx_exceed[0]]\n",
    "    \n",
    "    # 5) Compute T_lambda and ratio\n",
    "    T_lambda = 1.0 / lambda_max\n",
    "\n",
    "    # print(f\"\\n--- Valid Prediction Time (VPT) with threshold={threshold}, lambda_max={lambda_max} ---\")\n",
    "\n",
    "    T_VPT = (T_VPT - t_vals[0])  # Adjust T_VPT to be relative to the start time\n",
    "    ratio = T_VPT / T_lambda\n",
    "\n",
    "    return T_VPT, T_lambda, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b5c911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.686499Z",
     "iopub.status.busy": "2025-08-02T12:15:24.686227Z",
     "iopub.status.idle": "2025-08-02T12:15:24.703129Z",
     "shell.execute_reply": "2025-08-02T12:15:24.702491Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.686482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_attractor_deviation(predictions, targets, cube_size=(0.1, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Compute the Attractor Deviation (ADev) metric.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (numpy.ndarray): Predicted trajectories of shape (n, 3).\n",
    "        targets (numpy.ndarray): True trajectories of shape (n, 3).\n",
    "        cube_size (tuple): Dimensions of the cube (dx, dy, dz).\n",
    "\n",
    "    Returns:\n",
    "        float: The ADev metric.\n",
    "    \"\"\"\n",
    "    # Define the cube grid based on the range of the data and cube size\n",
    "    min_coords = np.min(np.vstack((predictions, targets)), axis=0)\n",
    "    max_coords = np.max(np.vstack((predictions, targets)), axis=0)\n",
    "\n",
    "    # Create a grid of cubes\n",
    "    grid_shape = ((max_coords - min_coords) / cube_size).astype(int) + 1\n",
    "\n",
    "    # Initialize the cube occupancy arrays\n",
    "    pred_cubes = np.zeros(grid_shape, dtype=int)\n",
    "    target_cubes = np.zeros(grid_shape, dtype=int)\n",
    "\n",
    "    # Map trajectories to cubes\n",
    "    pred_indices = ((predictions - min_coords) / cube_size).astype(int)\n",
    "    target_indices = ((targets - min_coords) / cube_size).astype(int)\n",
    "\n",
    "    # Mark cubes visited by predictions and targets\n",
    "    for idx in pred_indices:\n",
    "        pred_cubes[tuple(idx)] = 1\n",
    "    for idx in target_indices:\n",
    "        target_cubes[tuple(idx)] = 1\n",
    "\n",
    "    # Compute the ADev metric\n",
    "    adev = np.sum(np.abs(pred_cubes - target_cubes))\n",
    "    return adev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00486cc",
   "metadata": {},
   "source": [
    "### MIT-BIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826976d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.704118Z",
     "iopub.status.busy": "2025-08-02T12:15:24.703883Z",
     "iopub.status.idle": "2025-08-02T12:15:24.719476Z",
     "shell.execute_reply": "2025-08-02T12:15:24.718903Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.704079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def create_delay_embedding(signal, embed_dim):\n",
    "#     L = len(signal) - embed_dim + 1\n",
    "#     emb = np.zeros((L, embed_dim))\n",
    "#     for i in range(L):\n",
    "#         emb[i, :] = signal[i:i+embed_dim]\n",
    "#     return emb\n",
    "# import wfdb\n",
    "\n",
    "# # Download and load record and annotations for patient #100\n",
    "# record = wfdb.rdrecord('100', sampfrom=0, sampto=25002, pn_dir='mitdb')  # first 20,000 samples\n",
    "# annotation = wfdb.rdann('100', 'atr', sampfrom=0, sampto=25002, pn_dir='mitdb')\n",
    "# # Get input signal u(t) from the first channel\n",
    "# u = record.p_signal[:, 0] \n",
    "# u\n",
    "# # Normalize input\n",
    "# u_min = np.min(u)\n",
    "# u_max = np.max(u)\n",
    "# u_norm = (u - u_min) / (u_max - u_min)\n",
    "# fs = record.fs  # sampling frequency (should be 360 Hz)\n",
    "# t_vals = np.arange(len(u_norm)) / fs\n",
    "# emb_dim = 3\n",
    "# # inputs = u_norm\n",
    "# inputs = create_delay_embedding(u_norm, emb_dim)\n",
    "\n",
    "# # Create target array (heartbeat locations)\n",
    "# targets = np.zeros(len(u_norm))\n",
    "# targets[annotation.sample] = 1  # mark annotations as 1 (heartbeat)\n",
    "# targets = create_delay_embedding(targets, emb_dim)\n",
    "# data_size = len(inputs)\n",
    "# train_size = 15000\n",
    "# train_input = inputs[:train_size]\n",
    "# train_target = targets[:train_size]\n",
    "# test_input = inputs[train_size+1:]\n",
    "# test_target = targets[train_size+1:]\n",
    "# test_size = len(test_input)\n",
    "# print(f\"Total samples: {data_size}, train size: {train_size}, test size: {test_size}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6feca1d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.720359Z",
     "iopub.status.busy": "2025-08-02T12:15:24.720157Z",
     "iopub.status.idle": "2025-08-02T12:15:24.737284Z",
     "shell.execute_reply": "2025-08-02T12:15:24.736511Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.720344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1baaadf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.738285Z",
     "iopub.status.busy": "2025-08-02T12:15:24.738006Z",
     "iopub.status.idle": "2025-08-02T12:15:24.751329Z",
     "shell.execute_reply": "2025-08-02T12:15:24.750773Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.738262Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# all_horizons = list(range(10, 1001, 10))\n",
    "\n",
    "# nrmse_dict = defaultdict(list)\n",
    "# seeds = range(995, 996)\n",
    "\n",
    "# for seed in seeds:\n",
    "#     lstm_baseline = LSTMBaseline3D(\n",
    "#                         hidden_size=500,         # parameter budget ~ 4800\n",
    "#                         lr=1e-3,\n",
    "#                         epochs=80,\n",
    "#                         device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "#                         seed=seed)\n",
    "#     print(lstm_baseline.total_parameters())\n",
    "#     lstm_baseline.fit(train_input, train_target)\n",
    "\n",
    "#     # one-step roll-out to build an initial vector for auto-regressive mode\n",
    "#     init_vec = train_target[-1]                # last teacher-forced target\n",
    "#     lstm_preds = lstm_baseline.predict_open_loop(test_input)\n",
    "\n",
    "#     nrmse = evaluate_nrmse(lstm_preds, test_target, all_horizons)\n",
    "#     nrmse_dict['LSTM'].append(nrmse)\n",
    "#     # for horizon, value in nrmse.items():\n",
    "#     #     nrmse_dict[horizon].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244cba47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.752693Z",
     "iopub.status.busy": "2025-08-02T12:15:24.752139Z",
     "iopub.status.idle": "2025-08-02T12:15:24.767713Z",
     "shell.execute_reply": "2025-08-02T12:15:24.767135Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.752636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# nrmse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd37e962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.768538Z",
     "iopub.status.busy": "2025-08-02T12:15:24.768366Z",
     "iopub.status.idle": "2025-08-02T12:15:24.780700Z",
     "shell.execute_reply": "2025-08-02T12:15:24.780139Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.768524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# with open('lstmmitbih.json', 'w') as f:\n",
    "#     json.dump(nrmse_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cefd294f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.781644Z",
     "iopub.status.busy": "2025-08-02T12:15:24.781407Z",
     "iopub.status.idle": "2025-08-02T12:15:24.795478Z",
     "shell.execute_reply": "2025-08-02T12:15:24.794860Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.781623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# horizons = [300, 600, 1000]\n",
    "# print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "# print(\"-\" * 140)\n",
    "# print(f\"{'LSTM':<17}\")\n",
    "# print(\"-\" * 140)\n",
    "\n",
    "# for horizon in horizons:\n",
    "#     hfr_vals = [np.mean(hfr_nrmse[horizon]) for hfr_nrmse in nrmse_dict['LSTM']]\n",
    "\n",
    "#     print(f\"{horizon:<10}\", end=\" \")\n",
    "#     for vals in [hfr_vals]:\n",
    "#         mean = np.mean(vals)\n",
    "#         std = np.std(vals)\n",
    "#         print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b5ba0",
   "metadata": {},
   "source": [
    "### Sunspot (Monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7161afa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.796344Z",
     "iopub.status.busy": "2025-08-02T12:15:24.796145Z",
     "iopub.status.idle": "2025-08-02T12:15:24.808114Z",
     "shell.execute_reply": "2025-08-02T12:15:24.807533Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.796330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# file_path = '../RealWorld/datasets/SN_m_tot_V2.0.csv'\n",
    "\n",
    "# df = pd.read_csv(file_path, sep=';', header = None)\n",
    "# df\n",
    "# data = df.iloc[:, 3].values\n",
    "# dt = 1\n",
    "# dataset_size = len(data)\n",
    "# data = create_delay_embedding(data, 3)\n",
    "# print(f\"Dataset size: {dataset_size}\")\n",
    "\n",
    "# # Train/Test Split\n",
    "# train_end = 2000\n",
    "# train_input  = data[:train_end]\n",
    "# train_target = data[1:train_end+1]\n",
    "# test_input   = data[train_end:-1]\n",
    "# test_target  = data[train_end+1:]\n",
    "# y_test = test_target\n",
    "# n_test_steps = len(test_target)\n",
    "# time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "# print(f\"Train size: {len(train_input)}\\nTest size: {len(test_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "931fe915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.810694Z",
     "iopub.status.busy": "2025-08-02T12:15:24.810501Z",
     "iopub.status.idle": "2025-08-02T12:15:24.826789Z",
     "shell.execute_reply": "2025-08-02T12:15:24.826106Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.810680Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# lstm_baseline = LSTMBaseline3D(\n",
    "#                     hidden_size=32,         # parameter budget ~ 4800\n",
    "#                     lr=1e-3,\n",
    "#                     epochs=400,\n",
    "#                     device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "#                     seed=42)\n",
    "# lstm_baseline.fit(train_input, train_target)\n",
    "\n",
    "# # one-step roll-out to build an initial vector for auto-regressive mode\n",
    "# init_vec = train_target[-1]                # last teacher-forced target\n",
    "# lstm_preds = lstm_baseline.predict_open_loop(test_input)\n",
    "\n",
    "# nrmse = evaluate_nrmse(lstm_preds, test_target, horizons=[200, 400, 600, 800, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bb23aa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.827680Z",
     "iopub.status.busy": "2025-08-02T12:15:24.827479Z",
     "iopub.status.idle": "2025-08-02T12:15:24.840251Z",
     "shell.execute_reply": "2025-08-02T12:15:24.839683Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.827661Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b5dc631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.841048Z",
     "iopub.status.busy": "2025-08-02T12:15:24.840850Z",
     "iopub.status.idle": "2025-08-02T12:15:24.853162Z",
     "shell.execute_reply": "2025-08-02T12:15:24.852482Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.841027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# horizons = [300, 600, 1000]\n",
    "\n",
    "# all_horizons = list(range(10, 1001, 10))\n",
    "\n",
    "# nrmse_dict = defaultdict(list)\n",
    "# seeds = range(995, 996)\n",
    "\n",
    "# for seed in seeds:\n",
    "#     lstm_baseline = LSTMBaseline3D(\n",
    "#                         hidden_size=1000,         # parameter budget ~ 4800\n",
    "#                         lr=1e-3,\n",
    "#                         epochs=200,\n",
    "#                         device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "#                         seed=seed)\n",
    "#     print(lstm_baseline.total_parameters())\n",
    "#     lstm_baseline.fit(train_input, train_target)\n",
    "\n",
    "#     # one-step roll-out to build an initial vector for auto-regressive mode\n",
    "#     init_vec = train_target[-1]                # last teacher-forced target\n",
    "#     lstm_preds = lstm_baseline.predict_open_loop(test_input)\n",
    "\n",
    "#     nrmse = evaluate_nrmse(lstm_preds, test_target, all_horizons)\n",
    "#     nrmse_dict['LSTM'].append(nrmse)\n",
    "#     # for horizon, value in nrmse.items():\n",
    "#     #     nrmse_dict[horizon].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db726d39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.854139Z",
     "iopub.status.busy": "2025-08-02T12:15:24.853894Z",
     "iopub.status.idle": "2025-08-02T12:15:24.868064Z",
     "shell.execute_reply": "2025-08-02T12:15:24.867461Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.854071Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "# print(\"-\" * 140)\n",
    "# print(f\"{'LSTM':<17}\")\n",
    "# print(\"-\" * 140)\n",
    "\n",
    "# for horizon in horizons:\n",
    "#     hfr_vals = [np.mean(hfr_nrmse[horizon]) for hfr_nrmse in nrmse_dict['LSTM']]\n",
    "\n",
    "#     print(f\"{horizon:<10}\", end=\" \")\n",
    "#     for vals in [hfr_vals]:\n",
    "#         mean = np.mean(vals)\n",
    "#         std = np.std(vals)\n",
    "#         print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad54a6",
   "metadata": {},
   "source": [
    "### Santa Fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b15ec1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.868823Z",
     "iopub.status.busy": "2025-08-02T12:15:24.868639Z",
     "iopub.status.idle": "2025-08-02T12:15:24.881136Z",
     "shell.execute_reply": "2025-08-02T12:15:24.880464Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.868809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# file_path = 'RealWorld/datasets/santa-fe-time-series-competition-data-set-b-1.0.0/b1.txt'\n",
    "\n",
    "# df = pd.read_csv(file_path, header=None, sep=' ')\n",
    "# df\n",
    "# # Normalize the first column (column 0) of the DataFrame\n",
    "# df[0] = (df[0] - df[0].min()) / (df[0].max() - df[0].min())\n",
    "# data = df.iloc[:, 0].values\n",
    "# chosen_system = \"SantaFe\"\n",
    "# dt = 1\n",
    "# T_data = len(data)\n",
    "# data = create_delay_embedding(data, 3)\n",
    "# print(f\"Data length: {T_data}.\")\n",
    "\n",
    "# # Train/Test Split\n",
    "# train_end = 7000\n",
    "# train_input  = data[:train_end]\n",
    "# train_target = data[1:train_end+1]\n",
    "# test_input   = data[train_end:-1]\n",
    "# test_target  = data[train_end+1:]\n",
    "# y_test = test_target\n",
    "# n_test_steps = len(test_target)\n",
    "# time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "# print(f\"Train size: {len(train_input)}  \\nTest size: {len(test_input)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2434c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.882084Z",
     "iopub.status.busy": "2025-08-02T12:15:24.881863Z",
     "iopub.status.idle": "2025-08-02T12:15:24.898878Z",
     "shell.execute_reply": "2025-08-02T12:15:24.898356Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.882052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# horizons = [300, 600, 1000]\n",
    "\n",
    "# nrmse_dict = defaultdict(list)\n",
    "# seeds = range(995, 1025)\n",
    "\n",
    "# for seed in seeds:\n",
    "#     lstm_baseline = LSTMBaseline3D(\n",
    "#                         hidden_size=32,         # parameter budget ~ 4800\n",
    "#                         lr=1e-3,\n",
    "#                         epochs=400,\n",
    "#                         device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "#                         seed=seed)\n",
    "#     lstm_baseline.fit(train_input, train_target)\n",
    "\n",
    "#     # one-step roll-out to build an initial vector for auto-regressive mode\n",
    "#     init_vec = train_target[-1]                # last teacher-forced target\n",
    "#     lstm_preds = lstm_baseline.predict_open_loop(test_input)\n",
    "\n",
    "#     nrmse = evaluate_nrmse(lstm_preds, test_target, horizons)\n",
    "#     nrmse_dict['LSTM'].append(nrmse)\n",
    "#     # for horizon, value in nrmse.items():\n",
    "#     #     nrmse_dict[horizon].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eed92cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.899692Z",
     "iopub.status.busy": "2025-08-02T12:15:24.899478Z",
     "iopub.status.idle": "2025-08-02T12:15:24.912813Z",
     "shell.execute_reply": "2025-08-02T12:15:24.912211Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.899669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "# print(\"-\" * 140)\n",
    "# print(f\"{'LSTM':<17}\")\n",
    "# print(\"-\" * 140)\n",
    "\n",
    "# for horizon in horizons:\n",
    "#     hfr_vals = [np.mean(hfr_nrmse[horizon]) for hfr_nrmse in nrmse_dict['LSTM']]\n",
    "\n",
    "#     print(f\"{horizon:<10}\", end=\" \")\n",
    "#     for vals in [hfr_vals]:\n",
    "#         mean = np.mean(vals)\n",
    "#         std = np.std(vals)\n",
    "#         print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc09bd3",
   "metadata": {},
   "source": [
    "### BIDMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aa11860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.913731Z",
     "iopub.status.busy": "2025-08-02T12:15:24.913490Z",
     "iopub.status.idle": "2025-08-02T12:15:24.928668Z",
     "shell.execute_reply": "2025-08-02T12:15:24.927940Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.913698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import wfdb\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # ─── Load BIDMC Record ─────────────────────────────────────────────────────\n",
    "# record_id = 'bidmc01'\n",
    "# record = wfdb.rdrecord(record_id, pn_dir='bidmc', sampto=8 * 60 * 125)  # 8 mins at 125Hz\n",
    "# signals = record.p_signal  # shape: (60000, 5)\n",
    "# names = [n.strip().strip(',') for n in record.sig_name]\n",
    "\n",
    "# # ─── Get Indices of ECG Lead II and RESP ──────────────────────────────────\n",
    "# idx_ecg = names.index('II')     # ECG Lead II\n",
    "# idx_resp = names.index('RESP')  # Respiration signal\n",
    "\n",
    "# # ─── Parameters ────────────────────────────────────────────────────────────\n",
    "# N_train = 10000\n",
    "# N_test = 5000\n",
    "# emb_dim = 3\n",
    "\n",
    "# # ─── Select Signals ────────────────────────────────────────────────────────\n",
    "# u = signals[:, idx_ecg]   # input: ECG Lead II\n",
    "# v = signals[:, idx_resp]  # target: RESP\n",
    "\n",
    "# # ─── Normalize to [-1, 1] ──────────────────────────────────────────────────\n",
    "# u_norm = 2 * (u - np.min(u)) / (np.max(u) - np.min(u)) - 1\n",
    "# v_norm = 2 * (v - np.min(v)) / (np.max(v) - np.min(v)) - 1\n",
    "\n",
    "# # ─── Delay Embedding ───────────────────────────────────────────────────────\n",
    "# inputs = create_delay_embedding(u_norm, emb_dim)\n",
    "# targets = create_delay_embedding(v_norm, emb_dim)\n",
    "\n",
    "# # ─── Train/Test Split ──────────────────────────────────────────────────────\n",
    "# train_input = inputs[:N_train]\n",
    "# train_target = targets[:N_train]\n",
    "# test_input = inputs[N_train:N_train+N_test]\n",
    "# test_target = targets[N_train:N_train+N_test]\n",
    "\n",
    "# # ─── Summary ───────────────────────────────────────────────────────────────\n",
    "# print(f\"Train input shape:  {train_input.shape}\")\n",
    "# print(f\"Train target shape: {train_target.shape}\")\n",
    "# print(f\"Test input shape:   {test_input.shape}\")\n",
    "# print(f\"Test target shape:  {test_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0d4c49e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.929710Z",
     "iopub.status.busy": "2025-08-02T12:15:24.929474Z",
     "iopub.status.idle": "2025-08-02T12:15:24.942931Z",
     "shell.execute_reply": "2025-08-02T12:15:24.942395Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.929689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# horizons = [300, 600, 1000]\n",
    "\n",
    "# nrmse_dict = defaultdict(list)\n",
    "# seeds = range(995, 1025)\n",
    "\n",
    "# for seed in seeds:\n",
    "#     lstm_baseline = LSTMBaseline3D(\n",
    "#                         hidden_size=32,         # parameter budget ~ 4800\n",
    "#                         lr=1e-3,\n",
    "#                         epochs=400,\n",
    "#                         device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "#                         seed=seed)\n",
    "#     lstm_baseline.fit(train_input, train_target)\n",
    "\n",
    "#     # one-step roll-out to build an initial vector for auto-regressive mode\n",
    "#     init_vec = train_target[-1]                # last teacher-forced target\n",
    "#     lstm_preds = lstm_baseline.predict_open_loop(test_input)\n",
    "\n",
    "#     nrmse = evaluate_nrmse(lstm_preds, test_target, horizons)\n",
    "#     nrmse_dict['LSTM'].append(nrmse)\n",
    "#     # for horizon, value in nrmse.items():\n",
    "#     #     nrmse_dict[horizon].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36703cfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.943965Z",
     "iopub.status.busy": "2025-08-02T12:15:24.943723Z",
     "iopub.status.idle": "2025-08-02T12:15:24.955431Z",
     "shell.execute_reply": "2025-08-02T12:15:24.954862Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.943943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "# print(\"-\" * 140)\n",
    "# print(f\"{'LSTM':<17}\")\n",
    "# print(\"-\" * 140)\n",
    "\n",
    "# for horizon in horizons:\n",
    "#     hfr_vals = [np.mean(hfr_nrmse[horizon]) for hfr_nrmse in nrmse_dict['LSTM']]\n",
    "\n",
    "#     print(f\"{horizon:<10}\", end=\" \")\n",
    "#     for vals in [hfr_vals]:\n",
    "#         mean = np.mean(vals)\n",
    "#         std = np.std(vals)\n",
    "#         print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58809d1",
   "metadata": {},
   "source": [
    "### Canonical Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "578f4662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.956336Z",
     "iopub.status.busy": "2025-08-02T12:15:24.956163Z",
     "iopub.status.idle": "2025-08-02T12:15:24.968884Z",
     "shell.execute_reply": "2025-08-02T12:15:24.968121Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.956324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def lorenz_deriv(state, t, sigma=10.0, rho=28.0, beta=8.0/3.0):\n",
    "    x, y, z = state\n",
    "    dxdt = sigma * (y - x)\n",
    "    dydt = x*(rho - z) - y\n",
    "    dzdt = x*y - beta*z\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_lorenz_data(\n",
    "    initial_state=[1.0, 1.0, 1.0],\n",
    "    tmax=25.0,\n",
    "    dt=0.01,\n",
    "    sigma=10.0,\n",
    "    rho=28.0,\n",
    "    beta=8.0/3.0\n",
    "):\n",
    "    num_steps = int(tmax / dt) + 1 # +1 to include t=0\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(lorenz_deriv, initial_state, t_vals, args=(sigma, rho, beta))\n",
    "    return t_vals, sol\n",
    "\n",
    "def rossler_derivatives(state, t, a=0.2, b=0.2, c=5.7):\n",
    "    \"\"\"Compute time derivatives [dx/dt, dy/dt, dz/dt] for the Rössler system.\"\"\"\n",
    "    x, y, z = state\n",
    "    dxdt = -y - z\n",
    "    dydt = x + a * y\n",
    "    dzdt = b + z * (x - c)\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_rossler_data(\n",
    "    initial_state=[1.0, 0.0, 0.0],\n",
    "    tmax=25.0,\n",
    "    dt=0.01,\n",
    "    a=0.2,\n",
    "    b=0.2,\n",
    "    c=5.7\n",
    "):\n",
    "    \"\"\"\n",
    "    Numerically integrate Rössler equations x'(t), y'(t), z'(t) using odeint.\n",
    "    Returns:\n",
    "       t_vals: array of time points\n",
    "       sol   : array shape [num_steps, 3] of [x(t), y(t), z(t)]\n",
    "    \"\"\"\n",
    "    num_steps = int(tmax / dt)\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(rossler_derivatives, initial_state, t_vals, args=(a, b, c))\n",
    "    return t_vals, sol\n",
    "\n",
    "def chen_deriv(state, t, a=35.0, b=3.0, c=28.0):\n",
    "    \"\"\"\n",
    "    Computes derivatives [dx/dt, dy/dt, dz/dt] for Chen system:\n",
    "      dx/dt = a*(y - x)\n",
    "      dy/dt = (c - a)*x + c*y - x*z\n",
    "      dz/dt = x*y - b*z\n",
    "    \"\"\"\n",
    "    x, y, z = state\n",
    "    dxdt = a*(y - x)\n",
    "    dydt = (c - a)*x + c*y - x*z\n",
    "    dzdt = x*y - b*z\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_chen_data(\n",
    "    initial_state=[1.0, 1.0, 1.0],\n",
    "    tmax=50.0,\n",
    "    dt=0.01,\n",
    "    a=35.0,\n",
    "    b=3.0,\n",
    "    c=28.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Integrates Chen's system from 'initial_state' up to time 'tmax' with step size 'dt'.\n",
    "    Returns:\n",
    "      t_vals: time array of length T\n",
    "      sol   : array shape [T, 3], the trajectory [x(t), y(t), z(t)]\n",
    "    \"\"\"\n",
    "    num_steps = int(tmax / dt)\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(chen_deriv, initial_state, t_vals, args=(a, b, c))\n",
    "    return t_vals, sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8089a912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:15:24.970244Z",
     "iopub.status.busy": "2025-08-02T12:15:24.969652Z",
     "iopub.status.idle": "2025-08-02T12:15:24.984189Z",
     "shell.execute_reply": "2025-08-02T12:15:24.983440Z",
     "shell.execute_reply.started": "2025-08-02T12:15:24.970219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"input_dim\": [3],\n",
    "    \"hidden_size\": [500],\n",
    "    \"output_dim\": [3],\n",
    "    \"lr\": [1e-3],\n",
    "    \"epochs\": [80],\n",
    "    \"device\": ['cuda'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b326ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:19:05.455534Z",
     "iopub.status.busy": "2025-08-02T12:19:05.454995Z",
     "iopub.status.idle": "2025-08-02T12:19:05.466575Z",
     "shell.execute_reply": "2025-08-02T12:19:05.465718Z",
     "shell.execute_reply.started": "2025-08-02T12:19:05.455504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_grid_search(model_class, param_grid, model_name,\n",
    "                    output_path=\"grid_search_results.json\", f=generate_chen_data, lambda_max=0.9):\n",
    "    combos = list(itertools.product(*param_grid.values()))\n",
    "    param_keys = list(param_grid.keys())\n",
    "    print(f\"\\n== Initial grid search for {model_name} with {len(combos)} combinations ==\")\n",
    "\n",
    "    results = []\n",
    "    # horizons = list(range(10, 1001, 10))\n",
    "    horizons = [200, 400, 600, 800, 1000]\n",
    "    \n",
    "\n",
    "    for comb in tqdm(combos, desc=\"Grid Search\"):\n",
    "        params = dict(zip(param_keys, comb))\n",
    "        seed_scores_vpt = []\n",
    "        horizon_nrmse_all = {h: [] for h in horizons}\n",
    "        adev_scores = []\n",
    "        # ldev_scores = []\n",
    "\n",
    "        for initial_state in [[1.0, 1.0, 1.0], [1.0, 2.0, 3.0], [2.0, 1.5, 4.0]]:\n",
    "            tmax = 250\n",
    "            dt = 0.02\n",
    "            t_vals, lorenz_traj = f(\n",
    "                initial_state=initial_state,\n",
    "                tmax=tmax,\n",
    "                dt=dt\n",
    "            )\n",
    "\n",
    "            washout = 2000\n",
    "            t_vals = t_vals[washout:]\n",
    "            lorenz_traj = lorenz_traj[washout:]\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(lorenz_traj)\n",
    "            lorenz_traj = scaler.transform(lorenz_traj)\n",
    "\n",
    "            T_data = len(lorenz_traj)\n",
    "            for train_frac in [0.7, 0.75, 0.8]:\n",
    "                train_end = int(train_frac * (T_data - 1))\n",
    "                train_input = lorenz_traj[:train_end]\n",
    "                train_target = lorenz_traj[1:train_end + 1]\n",
    "                test_input = lorenz_traj[train_end:-1]\n",
    "                test_target = lorenz_traj[train_end + 1:]\n",
    "                n_test_steps = len(test_input)\n",
    "                initial_in = test_input[0]\n",
    "\n",
    "                for seed in np.arange(1, 5):\n",
    "                    model = model_class(**params, seed=seed)\n",
    "                    model.fit(train_input, train_target)\n",
    "                    preds = model.predict(initial_in, n_test_steps)\n",
    "\n",
    "                    # T_VPT_s, _, ratio = compute_valid_prediction_time(test_target, preds, t_vals, 0.4, lambda_max, dt)\n",
    "                    # seed_scores_vpt.append(ratio)\n",
    "\n",
    "                    horizon_nrmse = evaluate_nrmse(preds, test_target, horizons)\n",
    "                    for h in horizons:\n",
    "                        horizon_nrmse_all[h].append(horizon_nrmse[h])\n",
    "\n",
    "                    # adev = compute_attractor_deviation(preds, test_target)\n",
    "                    # adev_scores.append(adev)\n",
    "\n",
    "                    # ldev = compute_lyapunov_exponent(\"Lorenz\", preds, dt)\n",
    "                    # ldev_scores.append(ldev)\n",
    "\n",
    "        # mean_vpt = float(np.mean(seed_scores_vpt))\n",
    "        # std_vpt = float(np.std(seed_scores_vpt))\n",
    "        mean_nrmse_dict = {str(h): float(np.mean(horizon_nrmse_all[h])) for h in horizons}\n",
    "        std_nrmse_dict  = {str(h): float(np.std(horizon_nrmse_all[h]))  for h in horizons}\n",
    "        # mean_adev = float(np.mean(adev_scores))\n",
    "        # std_adev = float(np.std(adev_scores))\n",
    "        # mean_ldev = float(np.mean(ldev_scores))\n",
    "        # std_ldev = float(np.std(ldev_scores))\n",
    "\n",
    "        results.append({\n",
    "            \"params\": params,\n",
    "            # \"seed_scores_T_VPT\": seed_scores_vpt,\n",
    "            # \"mean_T_VPT\": mean_vpt,\n",
    "            # \"std_T_VPT\": std_vpt,\n",
    "            \"mean_NRMSEs\": mean_nrmse_dict,\n",
    "            \"std_NRMSEs\": std_nrmse_dict,\n",
    "            # \"mean_ADev\": mean_adev,\n",
    "            # \"std_ADev\": std_adev,\n",
    "            # \"mean_LDev\": mean_ldev,\n",
    "            # \"std_LDev\": std_ldev\n",
    "        })\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"\\nAll results saved to `{output_path}`\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "569374f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:19:07.803040Z",
     "iopub.status.busy": "2025-08-02T12:19:07.802489Z",
     "iopub.status.idle": "2025-08-02T12:19:47.344256Z",
     "shell.execute_reply": "2025-08-02T12:19:47.343532Z",
     "shell.execute_reply.started": "2025-08-02T12:19:07.803015Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Initial grid search for lstm with 1 combinations ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   0%|          | 0/1 [00:40<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLSTMBaseline3D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlstm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlstm_lorenz_best_param.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerate_lorenz_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_max\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mrun_grid_search\u001b[39m\u001b[34m(model_class, param_grid, model_name, output_path, f, lambda_max)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m np.arange(\u001b[32m1\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m     47\u001b[39m     model = model_class(**params, seed=seed)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     preds = model.predict(initial_in, n_test_steps)\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# T_VPT_s, _, ratio = compute_valid_prediction_time(test_target, preds, t_vals, 0.4, lambda_max, dt)\u001b[39;00m\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# seed_scores_vpt.append(ratio)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mLSTMBaseline3D.fit\u001b[39m\u001b[34m(self, x_np, y_np)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.epochs):\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mself\u001b[39m.optim.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_hidden\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     pred   = \u001b[38;5;28mself\u001b[39m.head(out)\n\u001b[32m     58\u001b[39m     loss   = \u001b[38;5;28mself\u001b[39m.crit(pred, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1124\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1121\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     result = _VF.lstm(\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1138\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1145\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1146\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "run_grid_search(LSTMBaseline3D, grid, \"lstm\", output_path=\"lstm_lorenz_best_param.json\", f=generate_lorenz_data, lambda_max=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6aed0f-e37b-4161-94a8-ae21d023e810",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc29e9-cf3f-4b08-87e2-979968a1e3b0",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
